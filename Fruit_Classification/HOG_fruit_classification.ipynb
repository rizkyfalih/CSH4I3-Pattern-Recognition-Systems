{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOG_fruit_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0E8Doae_cSg7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Fruit Classification using Random Forest with LBP and HOG Algorithm on Feature Extraction\n",
        "\n",
        "Create by **Raden Rizky Falih P**\n",
        "<br>NIM **1301154211**"
      ]
    },
    {
      "metadata": {
        "id": "ta7P7hAOcZLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load dataset from my drive"
      ]
    },
    {
      "metadata": {
        "id": "Xe3uM9WdcPm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c4c74f1a-35b3-4be1-80c5-cdd77b2456dd"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5HbcqlYlcdkZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Forest with HOG on Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "ngEXUlHycnsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cada9c54-7d83-4254-e5ab-f40b425f67f7"
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "!pip install imutils\n",
        "import imutils\n",
        "\n",
        "# initialize the data matrix and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "# path for datasets\n",
        "# path for apple\n",
        "apple1 = 'gdrive/My Drive/dataset/fruit/apple_1/'\n",
        "apple2 = 'gdrive/My Drive/dataset/fruit/apple_2/'\n",
        "apple3 = 'gdrive/My Drive/dataset/fruit/apple_3/'\n",
        "apple4 = 'gdrive/My Drive/dataset/fruit/apple_4/'\n",
        "apple5 = 'gdrive/My Drive/dataset/fruit/apple_5/'\n",
        "\n",
        "# path for banana\n",
        "banana1 = 'gdrive/My Drive/dataset/fruit/banana_1/'\n",
        "banana2 = 'gdrive/My Drive/dataset/fruit/banana_2/'\n",
        "banana3 = 'gdrive/My Drive/dataset/fruit/banana_3/'\n",
        "banana4 = 'gdrive/My Drive/dataset/fruit/banana_4/'\n",
        "\n",
        "# path for lemon\n",
        "lemon1 = 'gdrive/My Drive/dataset/fruit/lemon_1/'\n",
        "lemon2 = 'gdrive/My Drive/dataset/fruit/lemon_2/'\n",
        "lemon3 = 'gdrive/My Drive/dataset/fruit/lemon_3/'\n",
        "lemon4 = 'gdrive/My Drive/dataset/fruit/lemon_4/'\n",
        "lemon5 = 'gdrive/My Drive/dataset/fruit/lemon_5/'\n",
        "lemon6 = 'gdrive/My Drive/dataset/fruit/lemon_6/'\n",
        "\n",
        "# path for lime\n",
        "lime1 = 'gdrive/My Drive/dataset/fruit/lime_1/'\n",
        "lime2 = 'gdrive/My Drive/dataset/fruit/lime_2/'\n",
        "lime3 = 'gdrive/My Drive/dataset/fruit/lime_3/'\n",
        "lime4 = 'gdrive/My Drive/dataset/fruit/lime_4/'\n",
        "\n",
        "# path for orange\n",
        "orange1 = 'gdrive/My Drive/dataset/fruit/orange_1/'\n",
        "orange2 = 'gdrive/My Drive/dataset/fruit/orange_2/'\n",
        "orange3 = 'gdrive/My Drive/dataset/fruit/orange_3/'\n",
        "orange4 = 'gdrive/My Drive/dataset/fruit/orange_4/'\n",
        "\n",
        "# path for peach\n",
        "peach1 = 'gdrive/My Drive/dataset/fruit/peach_1/'\n",
        "peach2 = 'gdrive/My Drive/dataset/fruit/peach_2/'\n",
        "peach3 = 'gdrive/My Drive/dataset/fruit/peach_3/'\n",
        "\n",
        "# path for pear\n",
        "pear1 = 'gdrive/My Drive/dataset/fruit/pear_1/'\n",
        "pear2 = 'gdrive/My Drive/dataset/fruit/pear_2/'\n",
        "pear3 = 'gdrive/My Drive/dataset/fruit/pear_3/'\n",
        "pear4 = 'gdrive/My Drive/dataset/fruit/pear_4/'\n",
        "pear7 = 'gdrive/My Drive/dataset/fruit/pear_7/'\n",
        "pear8 = 'gdrive/My Drive/dataset/fruit/pear_8/'\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h3GV1R5ddwyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def HOG(imagePath):\n",
        "    # load the image, convert it to grayscale, and detect edges\n",
        "    image = cv2.imread(imagePath)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edged = imutils.auto_canny(gray)\n",
        "\n",
        "    # find contours in the edge map, keeping only the largest one which\n",
        "    # is presmumed to be the car logo\n",
        "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "      cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "    # extract the logo of the car and resize it to a canonical width\n",
        "    # and height\n",
        "    (x, y, w, h) = cv2.boundingRect(c)\n",
        "    fruit = gray[y:y + h, x:x + w]\n",
        "    fruit = cv2.resize(fruit, (200, 100))\n",
        "\n",
        "    # extract Histogram of Oriented Gradients from the logo\n",
        "    H = feature.hog(fruit, orientations=9, pixels_per_cell=(10, 10),\n",
        "      cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\") \n",
        "    \n",
        "    return H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jmr0obbIe46i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7aa10c06-eb4c-4efa-8537-b410210c3d18"
      },
      "cell_type": "code",
      "source": [
        "# loop over the training images\n",
        "# loop for apple datasets\n",
        "for fld, f in enumerate(os.listdir(apple1)):\n",
        "    hist = HOG(apple1+f)\n",
        "    labels.append('apple')\n",
        "    data.append(hist)\n",
        "\n",
        "for fld, f in enumerate(os.listdir(apple2)):\n",
        "    hist = HOG(apple2+f)\n",
        "    labels.append('apple')\n",
        "    data.append(hist)\n",
        "\n",
        "for fld, f in enumerate(os.listdir(apple3)):\n",
        "    hist = HOG(apple3+f)\n",
        "    labels.append('apple')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(apple4)):\n",
        "    hist = HOG(apple4+f)\n",
        "    labels.append('apple')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(apple5)):\n",
        "    hist = HOG(apple5+f)\n",
        "    labels.append('apple')\n",
        "    data.append(hist)\n",
        "    \n",
        "# loop for banana datasets\n",
        "for fld, f in enumerate(os.listdir(banana1)):\n",
        "    hist = HOG(banana1+f)\n",
        "    labels.append('banana')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(banana2)):\n",
        "    hist = HOG(banana2+f)\n",
        "    labels.append('banana')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(banana3)):\n",
        "    hist = HOG(banana3+f)\n",
        "    labels.append('banana')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(banana4)):\n",
        "    hist = HOG(banana4+f)\n",
        "    labels.append('banana')\n",
        "    data.append(hist)\n",
        "\n",
        "# loop for lemon datasets\n",
        "for fld, f in enumerate(os.listdir(lemon1)):\n",
        "    hist = HOG(lemon1+f)\n",
        "    labels.append('lemon')\n",
        "    data.append(hist)\n",
        "\n",
        "for fld, f in enumerate(os.listdir(lemon2)):\n",
        "    hist = HOG(lemon2+f)\n",
        "    labels.append('lemon')\n",
        "    data.append(hist)\n",
        "\n",
        "for fld, f in enumerate(os.listdir(lemon3)):\n",
        "    hist = HOG(lemon3+f)\n",
        "    labels.append('lemon')\n",
        "    data.append(hist)\n",
        "\n",
        "# ======= ERROR When Extract the feature =======\n",
        "\n",
        "# for fld, f in enumerate(os.listdir(lemon4)):\n",
        "#     hist = HOG(lemon4+f)\n",
        "#     labels.append('lemon')\n",
        "#     data.append(hist)\n",
        "    \n",
        "# for fld, f in enumerate(os.listdir(lemon5)):\n",
        "#     hist = HOG(lemon5+f)\n",
        "#     labels.append('lemon')\n",
        "#     data.append(hist)\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "for fld, f in enumerate(os.listdir(lemon6)):\n",
        "    hist = HOG(lemon6+f)\n",
        "    labels.append('lemon')\n",
        "    data.append(hist)\n",
        "    \n",
        "# loop for lime datasets\n",
        "for fld, f in enumerate(os.listdir(lime1)):\n",
        "    hist = HOG(lime1+f)\n",
        "    labels.append('lime')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(lime2)):\n",
        "    hist = HOG(lime2+f)\n",
        "    labels.append('lime')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(lime3)):\n",
        "    hist = HOG(lime3+f)\n",
        "    labels.append('lime')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(lime4)):\n",
        "    hist = HOG(lime4+f)\n",
        "    labels.append('lime')\n",
        "    data.append(hist)\n",
        "\n",
        "# loop for orange datasets\n",
        "for fld, f in enumerate(os.listdir(orange1)):\n",
        "    hist = HOG(orange1+f)\n",
        "    labels.append('orange')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(orange2)):\n",
        "    hist = HOG(orange2+f)\n",
        "    labels.append('orange')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(orange3)):\n",
        "    hist = HOG(orange3+f)\n",
        "    labels.append('orange')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(orange4)):\n",
        "    hist = HOG(orange4+f)\n",
        "    labels.append('orange')\n",
        "    data.append(hist)\n",
        "\n",
        "# loop for peach datasets\n",
        "for fld, f in enumerate(os.listdir(peach1)):\n",
        "    hist = HOG(peach1+f)\n",
        "    labels.append('peach')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(peach2)):\n",
        "    hist = HOG(peach2+f)\n",
        "    labels.append('peach')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(peach3)):\n",
        "    hist = HOG(peach3+f)\n",
        "    labels.append('peach')\n",
        "    data.append(hist)\n",
        "\n",
        "# loop for pear datasets\n",
        "for fld, f in enumerate(os.listdir(pear1)):\n",
        "    hist = HOG(pear1+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(pear2)):\n",
        "    hist = HOG(pear2+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(pear3)):\n",
        "    hist = HOG(pear3+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(pear4)):\n",
        "    hist = HOG(pear4+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(pear7)):\n",
        "    hist = HOG(pear7+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)\n",
        "    \n",
        "for fld, f in enumerate(os.listdir(pear8)):\n",
        "    hist = HOG(pear8+f)\n",
        "    labels.append('pear')\n",
        "    data.append(hist)  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
            "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZjujEzqNfcLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C1ooruFjfeeL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build a model\n",
        "model = RandomForestClassifier(n_estimators=12, n_jobs=-1)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# save the model\n",
        "filename = 'model_hog.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ma3AZ9vfhgJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c1ce0ee8-34ee-458e-b164-90f711eef40a"
      },
      "cell_type": "code",
      "source": [
        "# load model\n",
        "clf = pickle.load(open('model_hog.sav', 'rb'))\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pear', 'orange', 'orange', ..., 'apple', 'banana', 'apple'],\n",
              "      dtype='<U6')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "sfHlI9E6fjLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e316b74-3d0e-4d36-ae41-3db02664ca0b"
      },
      "cell_type": "code",
      "source": [
        "acc_test = clf.score(X_test, y_test)\n",
        "print(\"Accuracy testing: \",acc_test)\n",
        "\n",
        "acc_train = clf.score(X_train, y_train)\n",
        "print(\"Accuracy training: \",acc_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy testing:  0.9230550419570474\n",
            "Accuracy training:  0.9994665908040254\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}